{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "pd.set_option('display.max_rows', 200) # 设置显示最大行数\n",
    "pd.set_option('display.max_columns', 200) # 设置显示最大列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for path in os.listdir(\"../data/NG/P1000/Report_P1000_Time\"):\n",
    "    id = path\n",
    "    ids.append(id)\n",
    "data_NG = pd.DataFrame(columns=['id'])\n",
    "data_NG['id'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 0\n",
    "feature_dic = {}\n",
    "for i in tqdm(range(0,140,10)):\n",
    "    folder = \"../data/NG/P\"+str(1000+i)+\"/\"\n",
    "    for feature_name in (os.listdir(folder)):\n",
    "        for feature_csv in os.listdir(folder+feature_name):\n",
    "            id = feature_csv\n",
    "            csv_num = (np.array(pd.read_csv(folder+feature_name+'/'+feature_csv)))\n",
    "            id_idx = data_NG.loc[data_NG['id']==id].index.values[0]\n",
    "            if(len(csv_num)!=0):\n",
    "                feature_mean = csv_num.mean()\n",
    "                feature_max = csv_num.max()\n",
    "                feature_min = csv_num.min()\n",
    "                feature_std = csv_num.std()\n",
    "                skewness = stats.skew(csv_num)[0]\n",
    "                kurtosis = stats.kurtosis(csv_num)[0]\n",
    "                volatility = feature_std / feature_mean\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_mean'] = feature_mean\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_min'] = feature_min\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_max'] = feature_max\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_std'] = feature_std\n",
    "            else:\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_mean'] = None\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_min'] = None\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_max'] = None\n",
    "                data_NG.loc[id_idx,str(feature_index)+'_std'] = None\n",
    "        feature_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for path in os.listdir(\"../data/OK/P1000/Report_P1000_Time\"):\n",
    "    id = path\n",
    "    ids.append(id)\n",
    "data_OK = pd.DataFrame(columns=['id'])\n",
    "data_OK['id'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 0\n",
    "feature_dic = {}\n",
    "for i in tqdm(range(0,140,10)):\n",
    "    folder = \"../data/OK/P\"+str(1000+i)+\"/\"\n",
    "    for feature_name in (os.listdir(folder)):\n",
    "        for feature_csv in os.listdir(folder+feature_name):\n",
    "            id = feature_csv\n",
    "            csv_num = (np.array(pd.read_csv(folder+feature_name+'/'+feature_csv)))\n",
    "            id_idx = data_OK.loc[data_OK['id']==id].index.values[0]\n",
    "            if(len(csv_num)!=0):\n",
    "                feature_mean = csv_num.mean()\n",
    "                feature_max = csv_num.max()\n",
    "                feature_min = csv_num.min()\n",
    "                feature_std = csv_num.std()\n",
    "                skewness = stats.skew(csv_num)[0]\n",
    "                kurtosis = stats.kurtosis(csv_num)[0]\n",
    "                volatility = feature_std / feature_mean\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_mean'] = feature_mean\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_min'] = feature_min\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_max'] = feature_max\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_std'] = feature_std\n",
    "            else:\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_mean'] = None\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_min'] = None\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_max'] = None\n",
    "                data_OK.loc[id_idx,str(feature_index)+'_std'] = None\n",
    "        feature_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_OK['label']=0\n",
    "data_NG['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_NG,data_OK],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/data_4feature_all.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ddcf09acb84ee8d9c74b467d55b605b18b0deb8ae0e9e908e38f687216d25c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
