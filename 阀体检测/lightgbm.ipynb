{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,GridSearchCV  \n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from lofo import LOFOImportance, Dataset, plot_importance,FLOFOImportance\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn\n",
    "import datetime\n",
    "import catboost as cb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# pd.set_option('display.max_columns', 100) # 设置显示最大列数\n",
    "pd.set_option('display.max_rows', 300) # 设置显示最大行数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_4feas_plus_gere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas=[i  for i in data.columns.tolist() if i not in ['id','label']]\n",
    "\n",
    "x_train = data[feas]\n",
    "y_train = data['label']\n",
    "folds = 5\n",
    "seed = 2023#1111\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "cv_scores = []\n",
    "test_pre = []\n",
    "Feass = pd.DataFrame()\n",
    "train = np.zeros(x_train.shape[0])\n",
    "models = []\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "current_time = str(current_time).replace(' ','-')\n",
    "# os.mkdir('../log/'+current_time)\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(x_train, y_train)):\n",
    "    print('************************************ {} ************************************'.format(str(i+1)))\n",
    "    trn_x, trn_y, val_x, val_y = x_train.iloc[train_index], y_train[train_index], x_train.iloc[valid_index], y_train[valid_index]\n",
    "    param_grid = {'metric':'F1','n_estimators': 500, 'learning_rate': 0.2, 'max_depth':7,'num_leaves':127,  'bagging_fraction': 0.7, 'feature_fraction': 0.2}\n",
    "    # param_grid = {'metric':'F1','n_estimators': 500, 'learning_rate': 0.2, 'max_depth':7,'num_leaves':127,  'bagging_fraction': 0.8, 'feature_fraction': 0.8}\n",
    "    gbm = lgb.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "    gbm.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], eval_metric='l2', callbacks = [lgb.log_evaluation(period=50), lgb.early_stopping(stopping_rounds=50)])\n",
    "    models.append(gbm)\n",
    "    # joblib.dump(gbm, f\"../log/{current_time}/lgbm_model{i+1}.pkl\")\n",
    "    proba = gbm.predict_proba(val_x, num_iteration=gbm.best_iteration_)\n",
    "    val_pred = np.where(proba[:,0]>0.83,0,1)\n",
    "    train[valid_index] = val_pred\n",
    "    print(f1_score(val_pred,val_y))\n",
    "f1 = f1_score(train,y_train)\n",
    "print(f1)\n",
    "# os.rename(f'../log/{current_time}',f'../log/{f1}{current_time[:-6]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(columns=['name','importance'])\n",
    "importance['name']=models[-1].feature_name_\n",
    "idx = 0\n",
    "for gbm in models:\n",
    "    if(idx==0):\n",
    "        importance['importance']=gbm.feature_importances_\n",
    "    else:\n",
    "        importance['importance']+=gbm.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dic = {}\n",
    "for i in range(0,400):\n",
    "    df = importance[importance['name'].str.startswith(f\"{i}_\")]\n",
    "    score = df['importance'].sum()\n",
    "    imp_dic[i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_d = sorted(imp_dic.items(), key=lambda x: x[1], reverse=True)\n",
    "top_50 = sorted_d[:50]\n",
    "keys = [x[0] for x in top_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coloums_list = []\n",
    "for i in keys:\n",
    "    coloums_list.append(f'{i}_min')\n",
    "    coloums_list.append(f'{i}_max')\n",
    "    coloums_list.append(f'{i}_mean')\n",
    "    coloums_list.append(f'{i}_std')\n",
    "coloums_list.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(coloums_list,'../data/coloums_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_data = data[coloums_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas=[i  for i in cut_data.columns.tolist() if i not in ['id','label']]\n",
    "\n",
    "x_train = cut_data[feas]\n",
    "y_train = cut_data['label']\n",
    "folds = 5\n",
    "seed = 2023\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "# train = np.zeros(train_x.shape[0])\n",
    "\n",
    "cv_scores = []\n",
    "test_pre = []\n",
    "Feass = pd.DataFrame()\n",
    "train = np.zeros(x_train.shape[0])\n",
    "models = []\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "current_time = str(current_time).replace(' ','-')\n",
    "os.mkdir('../cut_model/'+current_time)\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(x_train, y_train)):\n",
    "    print('************************************ {} ************************************'.format(str(i+1)))\n",
    "    trn_x, trn_y, val_x, val_y = x_train.iloc[train_index], y_train[train_index], x_train.iloc[valid_index], y_train[valid_index]\n",
    "    gbm = lgb.LGBMClassifier(bagging_fraction=0.7, feature_fraction=0.2, learning_rate=0.2,\n",
    "               max_depth=7, metric='F1', n_estimators=500, num_leaves=127,\n",
    "               objective='binary')\n",
    "#     gbm = lgb.LGBMClassifier(bagging_fraction=0.8, feature_fraction=0.8, learning_rate=0.2,\n",
    "#             max_depth=7, metric='F1', n_estimators=500, num_leaves=127,\n",
    "#             objective='binary')\n",
    "    gbm.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], eval_metric='l2', callbacks = [lgb.log_evaluation(period=50), lgb.early_stopping(stopping_rounds=50)])\n",
    "    models.append(gbm)\n",
    "    joblib.dump(gbm, f\"../cut_model/{current_time}/lgbm_model{i+1}.pkl\")\n",
    "    proba = gbm.predict_proba(val_x, num_iteration=gbm.best_iteration_)\n",
    "    val_pred = np.where(proba[:,0]>0.85,0,1)\n",
    "    train[valid_index] = val_pred\n",
    "    print(f1_score(val_pred,val_y))\n",
    "f1 = f1_score(train,y_train)\n",
    "print(f1)\n",
    "os.rename(f'../cut_model/{current_time}',f'../cut_model/{f1}{current_time[:-6]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ddcf09acb84ee8d9c74b467d55b605b18b0deb8ae0e9e908e38f687216d25c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
